# PaliGemma Fine-tuning Scripts

4ê°œì˜ VL ë°ì´í„°ì…‹ì— ëŒ€í•œ PaliGemma fine-tuning ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

## ğŸ¯ ì§€ì› ë°ì´í„°ì…‹

1. **COCO Captioning** - ì´ë¯¸ì§€ ìº¡ì…”ë‹
2. **DocVQA** - ë¬¸ì„œ ì´ë¯¸ì§€ ì§ˆì˜ì‘ë‹µ
3. **GQA** - ì‹œê°ì  ì¶”ë¡  ë° ì§ˆì˜ì‘ë‹µ
4. **VQAv2** - ì¼ë°˜ ì‹œê°ì  ì§ˆì˜ì‘ë‹µ

## ğŸ“‹ Requirements

```bash
pip install torch transformers datasets peft bitsandbytes accelerate pillow wandb
```

## ğŸš€ ì‚¬ìš©ë²•

### 1. COCO Captioning

```bash
python finetuning/coco_captioning.py \
  --model_path google/paligemma-3b-pt-448 \
  --output_dir ./models/paligemma-coco \
  --num_epochs 3 \
  --batch_size 4 \
  --learning_rate 2e-4 \
  --use_wandb
```

### 2. DocVQA

```bash
python finetuning/docvqa.py \
  --model_path google/paligemma-3b-pt-448 \
  --output_dir ./models/paligemma-docvqa \
  --num_epochs 5 \
  --batch_size 4 \
  --learning_rate 2e-4
```

### 3. GQA (Visual Reasoning)

```bash
python finetuning/gqa.py \
  --model_path google/paligemma-3b-pt-448 \
  --output_dir ./models/paligemma-gqa \
  --num_epochs 3 \
  --batch_size 4 \
  --learning_rate 2e-4
```

### 4. VQAv2

```bash
python finetuning/vqav2.py \
  --model_path google/paligemma-3b-pt-448 \
  --output_dir ./models/paligemma-vqav2 \
  --num_epochs 3 \
  --batch_size 4 \
  --learning_rate 2e-4
```

## âš™ï¸ ì£¼ìš” ê¸°ëŠ¥

### ğŸ”§ 4-bit Quantization
- **BitsAndBytes** NF4 quantization ì‚¬ìš©
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 75% ê°ì†Œ
- í•™ìŠµ ì†ë„ ìœ ì§€

### ğŸ’¾ Gradient Checkpointing
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì  í•™ìŠµ
- í° ë°°ì¹˜ ì‚¬ì´ì¦ˆ ê°€ëŠ¥

### ğŸ¯ LoRA (Low-Rank Adaptation)
- íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  fine-tuning
- Rank: 16, Alpha: 32
- Target modules: attention & FFN layers

## ğŸ“Š ê¶Œì¥ í•˜ì´í¼íŒŒë¼ë¯¸í„°

| Dataset | Epochs | Batch Size | Learning Rate | Memory (GPU) |
|---------|--------|------------|---------------|--------------|
| COCO Caption | 3 | 4 | 2e-4 | ~18GB |
| DocVQA | 5 | 4 | 2e-4 | ~18GB |
| GQA | 3 | 4 | 2e-4 | ~18GB |
| VQAv2 | 3 | 4 | 2e-4 | ~18GB |

## ğŸ”„ í…ŒìŠ¤íŠ¸ìš© ì†Œê·œëª¨ í•™ìŠµ

ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ìƒ˜í”Œ ìˆ˜ë¥¼ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
python finetuning/vqav2.py \
  --model_path google/paligemma-3b-pt-448 \
  --output_dir ./models/test \
  --num_epochs 1 \
  --batch_size 2 \
  --max_train_samples 1000 \
  --max_eval_samples 100
```

## ğŸ“ˆ Monitoring with W&B

```bash
# ë¡œê·¸ì¸ (ìµœì´ˆ 1íšŒ)
wandb login

# í•™ìŠµ ì‹œ --use_wandb í”Œë˜ê·¸ ì¶”ê°€
python finetuning/coco_captioning.py \
  --model_path google/paligemma-3b-pt-448 \
  --output_dir ./models/paligemma-coco \
  --use_wandb \
  --wandb_project my-paligemma-project
```

## ğŸ“ ëª¨ë¸ ë³‘í•© (Merging)

í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë¸ë“¤ì„ ë³‘í•©í•˜ë ¤ë©´:

```bash
python merge_vlm.py \
  --base_model google/paligemma-3b-pt-448 \
  --model_a ./models/paligemma-vqav2 \
  --model_b ./models/paligemma-coco \
  --output ./models/merged-vqa-caption \
  --mode ties \
  --density 0.3
```

## ğŸ’¡ Tips

1. **ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ**: batch_size ì¤„ì´ê¸° ë˜ëŠ” gradient_accumulation_steps ëŠ˜ë¦¬ê¸°
2. **ë¹ ë¥¸ ìˆ˜ë ´**: learning_rateë¥¼ 3e-4ë¡œ ë†’ì´ê¸° (ë‹¨, overfitting ì£¼ì˜)
3. **ê¸´ í…ìŠ¤íŠ¸**: DocVQAëŠ” max_length=256 ì‚¬ìš© (ë¬¸ì„œ ì´í•´)
4. **ë°ì´í„°ì…‹ í¬ê¸°**: ì „ì²´ í•™ìŠµì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼ (VQAv2 ~400k samples)

## ğŸ› Troubleshooting

### CUDA Out of Memory
```bash
# batch_size ì¤„ì´ê¸°
--batch_size 2

# ë˜ëŠ” ë” aggressiveí•œ gradient accumulation
--gradient_accumulation_steps 8
```

### Dataset Loading Error
- ì¼ë¶€ ë°ì´í„°ì…‹ì€ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ í•„ìš”
- HuggingFace ê³„ì • ë¡œê·¸ì¸ í™•ì¸: `huggingface-cli login`

### BitsAndBytes Error
```bash
# CUDA ë²„ì „ í™•ì¸
pip install bitsandbytes --upgrade
```
